{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zunaed-farabe/MH-project/blob/main/Meta_Heuristic_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install deap"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCEoI9h-ykYL",
        "outputId": "e9cd6d19-2ea5-4e8e-ce56-57abf00d77c1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deap\n",
            "  Downloading deap-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.4/135.4 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deap) (1.25.2)\n",
            "Installing collected packages: deap\n",
            "Successfully installed deap-1.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ru4EVfJ6yiJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading data"
      ],
      "metadata": {
        "id": "Vmo_g44SN5nJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_vrp_file(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    data = {}\n",
        "    section = None\n",
        "    for line in lines:\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            continue\n",
        "        elif line.startswith('COMMENT'):\n",
        "            pass\n",
        "        elif line.startswith('NAME'):\n",
        "            data['name'] = line.split(':')[1].strip()\n",
        "        elif line.startswith('TYPE'):\n",
        "            data['type'] = line.split(':')[1].strip()\n",
        "        elif line.startswith('DIMENSION'):\n",
        "            data['dimension'] = int(line.split(':')[1].strip())\n",
        "        elif line.startswith('EDGE_WEIGHT_TYPE'):\n",
        "            data['edge_weight_type'] = line.split(':')[1].strip()\n",
        "        elif line.startswith('CAPACITY'):\n",
        "            data['capacity'] = int(line.split(':')[1].strip())\n",
        "        elif line.startswith('NODE_COORD_SECTION'):\n",
        "            section = 'node_coords'\n",
        "            data['node_coords'] = []\n",
        "        elif line.startswith('DEMAND_SECTION'):\n",
        "            section = 'demands'\n",
        "            data['demands'] = []\n",
        "        elif line.startswith('DEPOT_SECTION'):\n",
        "            section = 'depots'\n",
        "            data['depots'] = []\n",
        "        elif section == 'node_coords':\n",
        "            node_id, x, y = map(float, line.split())\n",
        "            data['node_coords'].append((node_id, x, y))\n",
        "        elif section == 'demands':\n",
        "            node_id, demand = map(int, line.split())\n",
        "            data['demands'].append((node_id, demand))\n",
        "        elif section == 'depots':\n",
        "            if line.startswith('EOF'):\n",
        "              break\n",
        "            else:\n",
        "              node_id = int(line.split()[0])\n",
        "              data['depots'].append(node_id)\n",
        "\n",
        "    return data\n",
        "\n",
        "file_path = '/content/gil262.vrp'\n",
        "vrp_data = read_vrp_file(file_path)\n",
        "\n",
        "# print(vrp_data)\n",
        "# display(vrp_data[\"node_coords\"][10:30])"
      ],
      "metadata": {
        "id": "zz9xzvqgqrqX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(vrp_data[\"node_coords\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvsIug0l2vSu",
        "outputId": "8a23b280-f5c0-4548-e82c-8bcd799bfaeb"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "coordinates = []\n",
        "for cord in vrp_data[\"node_coords\"]:\n",
        "  coordinates.append([cord[1], cord[1]])\n",
        "\n",
        "array_coord = np.array(coordinates)\n",
        "# Find the minimum value\n",
        "min_val = np.min(array_coord)\n",
        "print(\"Minimum value:\", min_val)\n",
        "\n",
        "# Find the maximum value\n",
        "max_val = np.max(array_coord)\n",
        "print(\"Maximum value:\", max_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lmpu_cbU0GFI",
        "outputId": "41bf0875-46f9-4ad9-fffb-a8f057689599"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimum value: -99.0\n",
            "Maximum value: 99.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the size of the original array\n",
        "size = array_coord.shape[0]\n",
        "\n",
        "# Create a square matrix of the same size filled with zeros\n",
        "square_matrix = np.zeros((size, size))\n",
        "\n",
        "# Assign the original values to their corresponding positions in the square matrix\n",
        "for i, (x, y) in enumerate(array_coord):\n",
        "    square_matrix[i, 0] = x\n",
        "    square_matrix[i, 1] = y\n",
        "\n",
        "\n",
        "print(square_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BrJ1GDcU4F6Z",
        "outputId": "dcef6b59-3cd4-409d-a0b6-20e835ef3c33"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-33. -33.   0. ...   0.   0.   0.]\n",
            " [-99. -99.   0. ...   0.   0.   0.]\n",
            " [-59. -59.   0. ...   0.   0.   0.]\n",
            " ...\n",
            " [ 40.  40.   0. ...   0.   0.   0.]\n",
            " [-60. -60.   0. ...   0.   0.   0.]\n",
            " [-60. -60.   0. ...   0.   0.   0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Low Rank + (1+1) Evolutionary Strategy"
      ],
      "metadata": {
        "id": "BQ20a-ZsOPqd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from scipy.sparse.linalg import svds\n",
        "\n",
        "def learn_low_rank_representation(X, s):\n",
        "    \"\"\"\n",
        "    Learn a low-rank representation of the dataset X.\n",
        "\n",
        "    Parameters:\n",
        "        X (numpy.ndarray): The dataset.\n",
        "        s (int): The number of rows/columns to sample.\n",
        "\n",
        "    Returns:\n",
        "        W (numpy.ndarray): The low-rank representation.\n",
        "        residual_error (numpy.ndarray): The residual error.\n",
        "    \"\"\"\n",
        "    # Random sampling of s rows/columns\n",
        "    indices = np.random.choice(X.shape[0], s, replace=False)\n",
        "    C = X[indices, :]\n",
        "    R = X[:, indices]\n",
        "\n",
        "    # Compute SVD of concatenated matrices\n",
        "    U, sigma, Vt = svds(np.hstack((C.T, R)), k=s)\n",
        "\n",
        "    # Extract the low-rank representation\n",
        "    W = np.dot(U[:, :s], np.diag(sigma[:s]))\n",
        "\n",
        "    # Calculate the residual error\n",
        "    reconstructed_X = np.dot(W, Vt[:s, :])\n",
        "\n",
        "\n",
        "    X = X.reshape(-1)  # [1, 2, 3, 4, 5, 6]\n",
        "    reconstructed_X = reconstructed_X.reshape(-1)\n",
        "    max_size = max(len(X), len(reconstructed_X))\n",
        "    X_padded = np.pad(X, (0, max_size - len(X)), mode='constant')\n",
        "    reconstructed_X_padded = np.pad(reconstructed_X, (0, max_size - len(reconstructed_X)), mode='constant')\n",
        "    residual_error = X_padded - reconstructed_X_padded\n",
        "\n",
        "\n",
        "    return W, residual_error\n",
        "\n",
        "# Define the fitness function\n",
        "def evaluate(individual,W,residual_error):\n",
        "\n",
        "\n",
        "    individual = individual.reshape(-1)\n",
        "    W = W.reshape(-1)\n",
        "    max_size = max(len(W), len(individual))\n",
        "    W_padded = np.pad(W, (0, max_size - len(W)), mode='constant')\n",
        "    individual = np.pad(individual, (0, max_size - len(individual)), mode='constant')\n",
        "    new_residual_error = W_padded.dot(individual)\n",
        "    return np.sum(np.square(new_residual_error - residual_error))\n",
        "\n",
        "def evolutionary_computation(W, residual_error, num_generations):\n",
        "    \"\"\"\n",
        "    Perform evolutionary computation using the (1+1)-Evolution Strategy.\n",
        "\n",
        "    Parameters:\n",
        "        W (numpy.ndarray): The low-rank representation.\n",
        "        residual_error (numpy.ndarray): The residual error.\n",
        "        num_generations (int): The number of generations.\n",
        "\n",
        "    Returns:\n",
        "        final_solution (numpy.ndarray): The final solution found by the evolutionary strategy.\n",
        "    \"\"\"\n",
        "    # Initialize the parent solution\n",
        "    parent = np.random.uniform(0, 1, W.shape[1])\n",
        "\n",
        "    # Perform (1+1)-ES\n",
        "    for _ in range(num_generations):\n",
        "        # Create an offspring by mutating the parent\n",
        "        offspring = parent + np.random.normal(0, 0.1, W.shape[1])\n",
        "\n",
        "        # Evaluate fitness of parent and offspring\n",
        "        parent_fitness = evaluate(parent,W,residual_error)\n",
        "        offspring_fitness = evaluate(offspring,W,residual_error)\n",
        "\n",
        "        # Select the better solution for the next generation\n",
        "        if offspring_fitness < parent_fitness:\n",
        "            parent = offspring\n",
        "\n",
        "    # The final solution is the parent after the last generation\n",
        "    final_solution = parent\n",
        "\n",
        "    return final_solution\n",
        "\n",
        "def main(X, s, num_generations):\n",
        "    \"\"\"\n",
        "    Main function to combine the steps of learning low-rank representation\n",
        "    and performing evolutionary computation.\n",
        "\n",
        "    Parameters:\n",
        "        X (numpy.ndarray): The dataset.\n",
        "        s (int): The number of rows/columns to sample.\n",
        "        num_generations (int): The number of generations for evolutionary computation.\n",
        "\n",
        "    Returns:\n",
        "        final_solution (numpy.ndarray): The final solution found by the evolutionary computation.\n",
        "    \"\"\"\n",
        "    # Step 1: Learning a low-rank representation\n",
        "    W, residual_error = learn_low_rank_representation(X, s)\n",
        "\n",
        "    # Step 2: Performing evolutionary computation\n",
        "    final_solution = evolutionary_computation(W, residual_error, num_generations)\n",
        "\n",
        "    return final_solution\n",
        "\n",
        "# Example usage:\n",
        "# X = np.random.rand(100, 100)\n",
        "X = square_matrix\n",
        "s = 2\n",
        "num_generations = 20\n",
        "result = main(X, s, num_generations)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUBcyha6Li6O",
        "outputId": "261bbfc6-2e18-43c1-d92f-8c9ea05b8c7e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.09446247 -0.01190985]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Low Rank + PSO\n"
      ],
      "metadata": {
        "id": "O69yelKmsOsH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse.linalg import svds\n",
        "import numpy as np\n",
        "\n",
        "def learn_low_rank_representation(X, s):\n",
        "    \"\"\"\n",
        "    Learn a low-rank representation of the dataset X.\n",
        "    Parameters:\n",
        "    X (numpy.ndarray): The dataset.\n",
        "    s (int): The number of rows/columns to sample.\n",
        "    Returns:\n",
        "    W (numpy.ndarray): The low-rank representation.\n",
        "    residual_error (numpy.ndarray): The residual error.\n",
        "    \"\"\"\n",
        "    # Random sampling of s rows/columns\n",
        "    indices = np.random.choice(X.shape[0], s, replace=False)\n",
        "    C = X[indices, :]\n",
        "    R = X[:, indices]\n",
        "    # Compute SVD of concatenated matrices\n",
        "    U, sigma, Vt = svds(np.hstack((C.T, R)), k=s)\n",
        "    # Extract the low-rank representation\n",
        "    W = np.dot(U[:, :s], np.diag(sigma[:s]))\n",
        "    # Calculate the residual error\n",
        "    reconstructed_X = np.dot(W, Vt[:s, :])\n",
        "    X = X.reshape(-1)  # [1, 2, 3, 4, 5, 6]\n",
        "    reconstructed_X = reconstructed_X.reshape(-1)\n",
        "    max_size = max(len(X), len(reconstructed_X))\n",
        "    X_padded = np.pad(X, (0, max_size - len(X)), mode='constant')\n",
        "    reconstructed_X_padded = np.pad(reconstructed_X, (0, max_size - len(reconstructed_X)), mode='constant')\n",
        "    residual_error = X_padded - reconstructed_X_padded\n",
        "    return W, residual_error\n",
        "\n",
        "# Define the fitness function\n",
        "def evaluate(individual, W, residual_error):\n",
        "    individual = individual.reshape(-1)\n",
        "    W = W.reshape(-1)\n",
        "    max_size = max(len(W), len(individual))\n",
        "    W_padded = np.pad(W, (0, max_size - len(W)), mode='constant')\n",
        "    individual = np.pad(individual, (0, max_size - len(individual)), mode='constant')\n",
        "    new_residual_error = W_padded.dot(individual)\n",
        "    return np.sum(np.square(new_residual_error - residual_error))\n",
        "\n",
        "def pso(W, residual_error, num_particles, num_generations, c1, c2, w):\n",
        "    \"\"\"\n",
        "    Perform Particle Swarm Optimization (PSO).\n",
        "    Parameters:\n",
        "    W (numpy.ndarray): The low-rank representation.\n",
        "    residual_error (numpy.ndarray): The residual error.\n",
        "    num_particles (int): The number of particles in the swarm.\n",
        "    num_generations (int): The number of generations.\n",
        "    c1 (float): The cognitive component.\n",
        "    c2 (float): The social component.\n",
        "    w (float): The inertia weight.\n",
        "    Returns:\n",
        "    best_solution (numpy.ndarray): The best solution found by PSO.\n",
        "    \"\"\"\n",
        "    # Initialize particle positions and velocities\n",
        "    particle_positions = np.random.uniform(0, 1, (num_particles, W.shape[1]))\n",
        "    particle_velocities = np.zeros_like(particle_positions)\n",
        "\n",
        "    # Initialize personal and global bests\n",
        "    personal_bests = particle_positions.copy()\n",
        "    personal_best_fitness = np.array([evaluate(p, W, residual_error) for p in personal_bests])\n",
        "    global_best_index = np.argmin(personal_best_fitness)\n",
        "    global_best = personal_bests[global_best_index]\n",
        "    global_best_fitness = personal_best_fitness[global_best_index]\n",
        "\n",
        "    # Perform PSO iterations\n",
        "    for _ in range(num_generations):\n",
        "        for i in range(num_particles):\n",
        "            # Update velocity\n",
        "            r1, r2 = np.random.uniform(0, 1, 2)\n",
        "            cognitive_component = c1 * r1 * (personal_bests[i] - particle_positions[i])\n",
        "            social_component = c2 * r2 * (global_best - particle_positions[i])\n",
        "            particle_velocities[i] = w * particle_velocities[i] + cognitive_component + social_component\n",
        "\n",
        "            # Update position\n",
        "            particle_positions[i] += particle_velocities[i]\n",
        "\n",
        "            # Update personal and global bests\n",
        "            current_fitness = evaluate(particle_positions[i], W, residual_error)\n",
        "            if current_fitness < personal_best_fitness[i]:\n",
        "                personal_bests[i] = particle_positions[i]\n",
        "                personal_best_fitness[i] = current_fitness\n",
        "                if personal_best_fitness[i] < global_best_fitness:\n",
        "                    global_best = personal_bests[i]\n",
        "                    global_best_fitness = personal_best_fitness[i]\n",
        "\n",
        "    best_solution = global_best\n",
        "    return best_solution\n",
        "\n",
        "def main(X, s, num_generations, num_particles=20, c1=2.0, c2=2.0, w=0.7):\n",
        "    \"\"\"\n",
        "    Main function to combine the steps of learning low-rank representation and performing PSO.\n",
        "    Parameters:\n",
        "    X (numpy.ndarray): The dataset.\n",
        "    s (int): The number of rows/columns to sample.\n",
        "    num_generations (int): The number of generations for PSO.\n",
        "    num_particles (int): The number of particles in the swarm.\n",
        "    c1 (float): The cognitive component.\n",
        "    c2 (float): The social component.\n",
        "    w (float): The inertia weight.\n",
        "    Returns:\n",
        "    final_solution (numpy.ndarray): The final solution found by PSO.\n",
        "    \"\"\"\n",
        "    # Step 1: Learning a low-rank representation\n",
        "    W, residual_error = learn_low_rank_representation(X, s)\n",
        "\n",
        "    # Step 2: Performing Particle Swarm Optimization\n",
        "    final_solution = pso(W, residual_error, num_particles, num_generations, c1, c2, w)\n",
        "\n",
        "    return final_solution\n",
        "\n",
        "# Example usage:\n",
        "\n",
        "X = square_matrix\n",
        "s = 2\n",
        "num_generations = 100\n",
        "result = main(X, s, num_generations)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ve9WWia2BNs5",
        "outputId": "6702c592-3cc4-4289-ad82-612ba5fe99d6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 8.39268432e-01 -5.88608354e-05]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KxZSuQtrNZmf"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMuHn4gziPsetOpUfj16Ky0",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}